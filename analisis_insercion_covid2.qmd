---
title: "Impacto del Cambio Metodológico Post-COVID en la Inserción Laboral"
author: "Carlos Pérez, Daniel Limón, Joaquín Vidal"
date: last-modified
format: 
  pdf:
    toc: true               # Índice de contenidos
    number-sections: true   # Numeración 1.1, 1.2...
    colorlinks: true        # Enlaces clicables en color
    papersize: a4           # Tamaño papel estándar europeo
    geometry:
      - top=25mm
      - left=25mm
      - right=25mm
      - bottom=25mm
    fig-pos: 'H'            # Intenta forzar que las gráficas salgan donde las pones
execute:
  warning: false
  message: false
editor: visual
---

# Resumen

*(Pendiente de redacción final)* Este estudio analiza la inserción laboral de XX,XXX egresados de universidades andaluzas, comparando la cohorte pre-pandemia (2018-2019) con las cohortes afectadas por la adaptación metodológica COVID-19.

# Introducción

-   Contexto: Breve descripción del cambio metodológico en la universidad andaluza durante la pandemia.
-   Hipótesis: El cambio forzoso a la docencia online/híbrida ha impactado negativamente en la calidad de la inserción laboral (mayor precariedad) en las cohortes afectadas.

# Metodología: Construcción de la Base de Datos

## Fuente de Datos

Los datos primarios proceden de la *Encuesta de Inserción Laboral de los Egresados de Universidades Públicas de Andalucía*, facilitados por el Instituto de Estadística y Cartografía de Andalucía (IECA). El estudio abarca un periodo longitudinal de cinco cohortes académicas, desde el curso 2018-2019 hasta el 2022-2023.

## Procesamiento y Harmonización

Dado que la estructura de los microdatos originales presentaba variaciones anuales en el esquema de columnas y separadores de archivo, se implementó un algoritmo de armonización para consolidar los ficheros anuales en un único dataframe maestro.

El proceso de limpieza y filtrado siguió las siguientes reglas de negocio estrictas:

1.  **Universo de Estudio:** Se seleccionaron exclusivamente los egresados de Grado (`tipo_estudio = 1`), excluyendo másteres y doctorados para garantizar la homogeneidad de la muestra.
2.  **Tratamiento de Valores Perdidos:**
    -   Se estandarizaron los códigos de "No consta" o "No aplica" (99, Q0) como valores perdidos (`NA`).
    -   Se aplicó un criterio de *casos completos* para las variables críticas del estudio: Cohorte, Rendimiento Académico, Rama de Enseñanza y Situación Laboral al primer año.
3.  **Definición de Variables Derivadas:**
    -   **Rama de Enseñanza (GRUPO):** Se reclasificó la variable `AMBITO` original (códigos de 4 dígitos) en 10 grandes grupos funcionales.
    -   **Calidad de la Inserción:** Se generó una variable binaria `CalidadContrato` basada en la jornada laboral al primer año (`TJORNADAA1T3`), donde la jornada parcial se considera un indicador de precariedad (1) frente a la jornada completa (0).

```{r}
#| label: ingesta-datos
#| echo: true
#| results: 'hide'

files <- c(
  "./microdatos/MicrodatILEUPA2018.csv",
  "./microdatos/MicrodatILEUPA2019.csv",
  "./microdatos/MicrodatILEUPA2020.csv",
  "./microdatos/MicrodatILEUPA2021.csv",
  "./microdatos/MicrodatILEUPA2022.csv"
)

# --- Lector que autodetecta separador ("," o ";") ---
read_csv_auto <- function(path) {
  if (!is.character(path) || length(path) != 1) stop("Ruta no válida.")
  if (!file.exists(path)) stop(paste("No existe el archivo:", path))
  first_line <- readLines(path, n = 1, warn = FALSE)
  if (grepl(";", first_line)) {
    df <- read.csv2(path, stringsAsFactors = FALSE, check.names = FALSE)
  } else {
    df <- read.csv(path,  stringsAsFactors = FALSE, check.names = FALSE)
  }
  df
}

# --- Unir data.frames con distinto set de columnas (rellena faltantes con NA) ---
rbind_union <- function(dflist) {
  all_names <- unique(unlist(lapply(dflist, names)))
  aligned <- lapply(dflist, function(x) {
    miss <- setdiff(all_names, names(x))
    if (length(miss) > 0) {
      for (m in miss) x[[m]] <- NA
    }
    x[, all_names, drop = FALSE]
  })
  do.call(rbind, aligned)
}

# --- Cargar todos los ficheros ---
lst <- lapply(files, read_csv_auto)
datos <- rbind_union(lst)
```

**Selección del Universo y Variables de Interés**

Sobre el conjunto consolidado, se aplicó un filtrado para restringir el análisis a las columnas relevantes (Renombrado de `CURSO` a `anio`) y al universo de egresados de Grado (`tipo_estudio == "1"`), excluyendo otros niveles formativos para garantizar la comparabilidad.

```{r}
#| label: seleccion-universo
#| echo: true
#| results: 'hide'

# --- Selección de columnas deseadas ---
# nombres base tal cual vienen en los microdatos
base_keep <- intersect(c("CURSO","TIPOESTUDIO","AMBITO","RENDIMIENTO"), names(datos))

# patrones de columnas adicionales (insensible a mayúsculas/minúsculas)
nm <- names(datos)
keep_extra <- nm[
  grepl("^ACTIVIDAD",  nm, ignore.case = TRUE) |
  grepl("^GRUPO_?COT", nm, ignore.case = TRUE) |  # GRUPOCOT o GRUPO_COT
  grepl("^TCONTRATO",  nm, ignore.case = TRUE) |
  grepl("^TJORNADA",   nm, ignore.case = TRUE)
]

cols_to_keep <- unique(c(base_keep, keep_extra))
tabla <- datos[, cols_to_keep, drop = FALSE]

# --- Renombrar CURSO -> anio, TIPOESTUDIO -> tipo_estudio (si existen) ---
if ("CURSO" %in% names(tabla))       names(tabla)[names(tabla) == "CURSO"]       <- "anio"
if ("TIPOESTUDIO" %in% names(tabla)) names(tabla)[names(tabla) == "TIPOESTUDIO"] <- "tipo_estudio"

datosdef=tabla[tabla$tipo_estudio=="1",]
```

**Tratamiento de Valores Ausentes (NAs)**

Se implementó una estrategia de limpieza estricta. Los códigos administrativos "99" (No consta) y "Q0" (Sin rendimiento) fueron recodificados como valores perdidos (NA). Posteriormente, se evaluó la tasa de completitud de los registros.

```{r}
#| label: limpieza-nas
#| echo: true
#| results: 'hide'

# Imputamos los NA a los 99
variables_objetivo_a_modificar <- c("GRUPOCOTA1T3","GRUPOCOTA2T3","GRUPOCOTA3T3","GRUPOCOTA4T3",
                                    "TCONTRATOA1T3","TCONTRATOA2T3","TCONTRATOA3T3","TCONTRATOA4T3",
                                    "TJORNADAA1T3","TJORNADAA2T3","TJORNADAA3T3","TJORNADAA4T3")
for (col in variables_objetivo_a_modificar) {
  datosdef[[col]][datosdef[[col]] == 99] <- NA
}
# Imputamos los NA a los Q0
datosdef[["RENDIMIENTO"]][datosdef[["RENDIMIENTO"]] == "Q0"] <- NA

# 1) Conteo de NO-NA solo en las variables objetivo (+ RENDIMIENTO)
vars_target <- unique(c("RENDIMIENTO", variables_objetivo_a_modificar))
vars_target <- vars_target[vars_target %in% names(datosdef)]

# Tratamos cadenas vacías como NA
datosdef[datosdef == ""] <- NA
```

**Generación del Dataset Analítico (`datos_analisis`)**

Finalmente, se construyeron las variables derivadas necesarias para la contrastación de hipótesis:

1.  Rama de Enseñanza (GRUPO): Normalización de la variable AMBITO.

2.  Calidad del Contrato (`CalidadContrato`): Variable dicotómica donde la jornada parcial (`TJORNADAA1T3 == 2`) se codifica como 1 (baja calidad) y el resto como 0.

El conjunto final datos_analisis contiene únicamente los registros completos (complete.cases) para las variables críticas, formateados como factores ordenados.

```{r}
#| label: construccion-analisis
#| echo: true

# 1) Grupo
datosdef$GRUPO <- ifelse(datosdef$AMBITO == 9999,
                         NA_integer_,
                         datosdef$AMBITO %/% 100)

datosdef$AMBITO <- NULL

# 2) Filtrar filas con claves completas: anio, RENDIMIENTO, GRUPO
datosdef_ok <- datosdef[!is.na(datosdef$anio) &
                        !is.na(datosdef$RENDIMIENTO) &
                        !is.na(datosdef$GRUPO), , drop = FALSE]

# 3) Construir dataset de análisis solo con las variables relevantes
vars_analisis <- c("anio", "RENDIMIENTO", "GRUPO", "TJORNADAA1T3")
vars_analisis <- vars_analisis[vars_analisis %in% names(datosdef_ok)]

datos_analisis <- datosdef_ok[, vars_analisis, drop = FALSE]

# 4) Eliminar casos sin información de jornada
datos_analisis <- datos_analisis[!is.na(datos_analisis$TJORNADAA1T3), , drop = FALSE]

# 5) Crear CalidadContrato SOLO a partir de TJORNADAA1T3
tmp <- datos_analisis$TJORNADAA1T3
if (is.character(tmp)) {
  suppressWarnings(tmp_num <- as.integer(tmp))
} else {
  tmp_num <- suppressWarnings(as.integer(tmp))
}

# Aquí asumimos (ajústalo si es al revés):
#   CalidadContrato = 1 -> contrato de mala calidad si TJORNADAA1T3 == 2
#   CalidadContrato = 0 -> contrato de buena calidad si TJORNADAA1T3 != 2
datos_analisis$CalidadContrato <- ifelse(tmp_num == 2L, 1L, 0L)

# 6) (Opcional) dejar solo las columnas finales
datos_analisis <- datos_analisis[, c("anio", "RENDIMIENTO", "GRUPO",
                                     "TJORNADAA1T3", "CalidadContrato"),
                                 drop = FALSE]


datos_analisis$anio <- factor(datos_analisis$anio,
                              levels = c("2018-2019","2019-2020","2020-2021",
                                         "2021-2022","2022-2023"),
                              ordered = TRUE)

datos_analisis$RENDIMIENTO <- factor(datos_analisis$RENDIMIENTO,
                                     levels = c("Q1","Q2","Q3","Q4"),
                                     ordered = TRUE)

library(dplyr)
library(ggplot2)
# Verificación final
glimpse(datos_analisis)
```

# Resultados Descriptivos

Objetivo: Validar que los grupos son comparables y observar tendencias "a simple vista"

## Caracterización de la Muestra

-   Uso de gtsummary para comparar variables demográficas y académicas (Rendimiento, Rama) entre el grupo Control (2018-19) y Tratamiento (2019-23).

-   Test estadístico de diferencias entre grupos (Chi-cuadrado).

## Análisis Exploratorio Visual:

-   Gráfico de barras: Tasa de Precariedad (Jornada Parcial) por Rama de Enseñanza.

-   Evolución temporal: Línea de tendencia de la precariedad a lo largo de los 5 años (para ver si hubo un "shock" en 2020).

# Análisis Inferencial

Objetivo: Aislar el efecto COVID de otras variables confusoras

Variable Intervención y modelo:

#\| label: creacion-intervencion-y-ajuste

#\| echo: true

#\| results: 'show'

\# CARGA DE LIBRERÍAS NECESARIAS

library(dplyr)

library(ggplot2)

library(gtsummary)

library(broom)

\# 1. CREACIÓN DE LA VARIABLE DE INTERVENCIÓN (Post-COVID)

\# La variable de intervención es el predictor clave para testar el efecto neto.

\# Definición: Pre-COVID (2018-2019) vs. Post-COVID (2019-2020 en adelante)

datos_analisis \<- datos_analisis %\>%

mutate(

\# Crear la variable binaria

Post_COVID = case_when(

anio == "2018-2019" \~ "Pre-COVID (Referencia)",

anio %in% c("2019-2020", "2020-2021", "2021-2022", "2022-2023") \~ "Post-COVID",

TRUE \~ NA_character\_

),

\# Asegurar que sea factor y la categoría de referencia sea Pre-COVID

Post_COVID = factor(Post_COVID,

levels = c("Pre-COVID (Referencia)", "Post-COVID"))

) %\>%

\# Asegurar que GRUPO y RENDIMIENTO sean factores para el modelo

mutate(

GRUPO = factor(GRUPO),

RENDIMIENTO = factor(RENDIMIENTO)

) %\>%

\# Eliminar NAs si quedan, aunque ya se hizo previamente

filter(!is.na(Post_COVID))

\# 2. ESPECIFICACIÓN Y AJUSTE DEL MODELO LOGÍSTICO

\# VD: CalidadContrato (Prob. de Precariedad, donde 1 es Precariedad)

\# VIs: Post_COVID (Foco), GRUPO (Control Obligatorio), RENDIMIENTO (Control)

modelo_logistico \<- glm(

CalidadContrato \~ Post_COVID + GRUPO + RENDIMIENTO,

data = datos_analisis,

family = binomial(link = "logit")

)

\# 3. PRESENTACIÓN DE RESULTADOS CON gtsummary (Tabla Académica)

tabla_modelo \<- modelo_logistico %\>%

tbl_regression(

exponentiate = TRUE, \# Mostrar Odds Ratios (OR) en lugar de log-odds

label = list(

Post_COVID \~ "Periodo de Intervención",

GRUPO \~ "Rama de Conocimiento",

RENDIMIENTO \~ "Rendimiento Académico"

),

pvalue_fun = \~style_pvalue(.x, digits = 3) \# Formato de p-valor

) %\>%

\# Añadir el N del modelo y la bondad de ajuste

add_n() %\>%

add_glance_source_note(label = list(

N = "N (Casos completos)",

AIC = "Criterio de Información de Akaike"

)) %\>%

\# Añadir el nombre del modelo

modify_caption("\*\*Tabla 1. Resultados de la Regresión Logística (Odds Ratios)\*\*")

\# Imprimir la tabla

tabla_modelo

Forest Plot:

#\| label: forest-plot-odds-ratios

#\| echo: true

#\| fig-height: 8 \# Altura ajustada para acomodar todos los coeficientes

#\| fig-width: 9

library(dplyr)

library(ggplot2)

library(broom)

\# 1. EXTRACCIÓN Y TRANSFORMACIÓN DE COEFICIENTES (broom)

\# Usamos tidy para extraer coeficientes, transformamos a OR e IC

datos_forest \<- tidy(modelo_logistico, exponentiate = TRUE, conf.int = TRUE) %\>%

\# Limpieza de nombres de términos para el gráfico

mutate(

\# Simplificar el nombre de la categoría Post-COVID

term = case_match(

term,

"Post_COVIDPost-COVID" \~ "Post-COVID vs Pre-COVID",

.default = term

),

\# Etiquetar GRUPO y RENDIMIENTO para la visualización

TermLabel = case_when(

grepl("\^GRUPO", term) \~ paste0("Rama ", sub("GRUPO", "", term)),

grepl("\^RENDIMIENTO", term) \~ paste0("Rendimiento ", sub("RENDIMIENTO", "", term)),

TRUE \~ term

),

\# Reordenar las categorías para un plot limpio: COVID, Rendimiento, Ramas

Categoria = case_when(

term == "Post-COVID vs Pre-COVID" \~ "A. Intervención Temporal (Foco)",

grepl("\^Rendimiento", TermLabel) \~ "B. Rendimiento Académico",

TRUE \~ "C. Ramas de Conocimiento"

)

) %\>%

\# Excluir el intercepto (no interpretable) y ordenar por Categoría

filter(term != "(Intercept)") %\>%

arrange(Categoria, estimate)

\# 2. GENERACIÓN DEL FOREST PLOT (ggplot2 minimalista)

forest_plot \<- datos_forest %\>%

ggplot(aes(x = estimate, y = reorder(TermLabel, estimate))) +

\# Añadir la línea de referencia (Odds Ratio = 1)

geom_vline(xintercept = 1, linetype = "dashed", color = "gray50", linewidth = 0.8) +

\# Dibujar los Intervalos de Confianza (IC 95%)

geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2,

color = "gray30") +

\# Dibujar los Odds Ratios (puntos)

geom_point(aes(color = Categoria), size = 3) +

\# Estilo y etiquetas

labs(

title = "Odds Ratios de Precariedad (Jornada Parcial) por Periodo, Rama y Rendimiento",

subtitle = "Modelo Logístico ajustado por variables confusoras. (Referencia: Pre-COVID, Intercepto de GRUPO y Q1 de Rendimiento)",

x = "Odds Ratio (OR) --- Mayor Precariedad ⟶",

y = ""

) +

\# Separar en facetas (opcional, pero ayuda a la lectura)

facet_grid(Categoria \~ ., scales = "free_y", space = "free_y") +

\# Estética (Minimalista y académica)

theme_bw() +

theme(

legend.position = "none",

axis.text.y = element_text(face = "bold"),

plot.title = element_text(face = "bold"),

strip.text.y = element_text(face = "bold")

) +

\# Escala logarítmica para ORs (mejora la simetría visual)

scale_x_log10(breaks = c(0.25, 0.5, 1, 2, 4)) +

\# Colores (ajustables)

scale_color_manual(values = c("A. Intervención Temporal (Foco)" = "#B22222",

"B. Rendimiento Académico" = "#006400",

"C. Ramas de Conocimiento" = "#1E90FF"))

\# Imprimir el gráfico

forest_plot

## Especificación del Modelo

-   Regresión Logística Binaria (glm).

-   VD: Probabilidad de Precariedad (CalidadContrato == 1).

-   VIs: Periodo COVID + Rama + Rendimiento Académico.

## Resultados del Modelo

-   Presentación de Odds Ratios (OR) e intervalos de confianza.

-   Forest Plot: Visualización de los coeficientes para ver qué ramas protegen más contra la precariedad.

# Discusión y Conclusiones

## Interpretación

¿Se confirma la hipótesis? (Si OR \> 1 en periodo COVID, sí afectó).

## Matices por rama

¿Afectó a todas las carreras por igual o sufrieron más las que requieren presencialidad (ej. Ciencias vs Humanidades)?

## Limitaciones

Uso de datos administrativos (sin datos de habilidades blandas). Esto ya lo podemos hablar y consideramos si hacemos mención de las soft skills o no.
